{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM Tensorflow Parameter Server on SageMaker Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this sample, we will demo how to run a deepfm sample code in tensorflow parameter server on sagemaker\n",
    "\n",
    "Notice:\n",
    "\n",
    "1. Dataset format is TFRecord\n",
    "\n",
    "2. This model training we will use **CPU** instances based on our experience, DeepFM script TF PS on CPU will more effective and saving cost. \n",
    "\n",
    "3. Using [SageMaker Python SDK 2.x](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)\n",
    "4. TensorFlow version is 1.14 or 1.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.session.Session()\n",
    "\n",
    "bucket = sess.default_bucket() # use default bucket to store data and model. you can change this to other buckets\n",
    "checkpoint_s3_uri = 's3://{}/deepfm-checkpoint'.format(bucket) #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_local_path = '/opt/ml/checkpoints'\n",
    "model_dir = 's3://{}/deepfm-ps-ckpt/{}'.format(bucket, datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "output_path= 's3://{}/deepfm-2021'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training, validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = f's3://{bucket}/data/train/'\n",
    "\n",
    "os.system(f'aws s3 cp ../data/train.tfrecords {training_data}train_1.tfrecords')\n",
    "os.system(f'aws s3 cp ../data/train.tfrecords {training_data}train_2.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data = f's3://{bucket}/data/validation/'\n",
    "\n",
    "os.system(f'aws s3 cp ../data/val.tfrecords {training_data}val_1.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.c5.4xlarge'\n",
    "train_instance_count = 2\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "\n",
    "train_max_run = 36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions = {'parameter_server': {'enabled': True}}\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {\n",
    "    'servable_model_dir': '/opt/ml/model', 'training_data_dir': '/opt/ml/input/data/training/',\n",
    "    'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "    'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "    'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': 0, 'enable_s3_shard': enable_s3_shard,\n",
    "    'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    #source_dir='./',\n",
    "    entry_point='DeepFM-dist-ps-for-multipleCPU-multiInstance.py',\n",
    "    \n",
    "    # S3 location where the checkpoint data and models can be exported to during training. \n",
    "    # It will be passed in the training script as one of the command line arguments. \n",
    "    model_dir=model_dir,\n",
    "    \n",
    "    # The S3 URI in which to persist checkpoints that the algorithm persists (if any) during training.\n",
    "    #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "\n",
    "    # The local path that the algorithm writes its checkpoints to. \n",
    "    # SageMaker will persist all files under this path to checkpoint_s3_uri continually during training. \n",
    "    # On job startup the reverse happens - data from the s3 location is downloaded to this path before the algorithm is started. \n",
    "    # If the path is unset then SageMaker assumes the checkpoints will be provided under /opt/ml/checkpoints/\n",
    "    #checkpoint_local_path = checkpoint_local_path,\n",
    "\n",
    "    # S3 location for saving the training result (model artifacts and output files). \n",
    "    # If not specified, results are stored to a default bucket.\n",
    "    output_path=output_path,\n",
    "    instance_type=train_instance_type,\n",
    "    instance_count=train_instance_count,\n",
    "    #volume_size = 500,\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    base_job_name=base_job_name,\n",
    "    framework_version='1.15.2',\n",
    "    py_version='py3',\n",
    "    #input_mode='Pipe',\n",
    "    distribution=distributions,\n",
    "    use_spot_instances=train_use_spot_instances,\n",
    "    max_wait=train_max_wait,\n",
    "    max_run=train_max_run,\n",
    "    debugger_hook_config=False, # Configuration for how debugging information is emitted with SageMaker Debugger. \n",
    "                                # If not specified, a default one is created using the estimatorâ€™s output_path, unless the region does not support SageMaker Debugger. \n",
    "                                # To disable SageMaker Debugger, set this parameter to False.\n",
    "    disable_profiler=True,  # Specifies whether Debugger monitoring and profiling will be disabled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_s3_uri = training_data # Path to training data\n",
    "validate_s3_uri = validation_data # Path to validation data\n",
    "\n",
    "if enable_s3_shard:\n",
    "    train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "else:\n",
    "    train_input = TrainingInput(train_s3_uri)\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "\n",
    "inputs = {training_channel_name:train_input, evaluation_channel_name:val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.c5.18xlarge'\n",
    "train_instance_count = 2\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "\n",
    "train_max_run = 36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions = {'parameter_server': {'enabled': True}}\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {\n",
    "    'servable_model_dir': '/opt/ml/model', 'training_data_dir': '/opt/ml/input/data/training/',\n",
    "    'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "    'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "    'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': 1, 'enable_s3_shard': enable_s3_shard,\n",
    "    'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    #source_dir='./',\n",
    "    entry_point='DeepFM-dist-ps-for-multipleCPU-multiInstance.py',\n",
    "    model_dir=model_dir,\n",
    "    #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "    #checkpoint_local_path = checkpoint_local_path,\n",
    "    output_path= output_path,\n",
    "    instance_type=train_instance_type,\n",
    "    instance_count=train_instance_count,\n",
    "    #volume_size = 500,\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    base_job_name=base_job_name,\n",
    "    framework_version='1.14',\n",
    "    py_version='py3',\n",
    "    input_mode='Pipe',\n",
    "    distribution=distributions,\n",
    "    use_spot_instances=train_use_spot_instances,\n",
    "    max_wait=train_max_wait,\n",
    "    max_run=train_max_run,\n",
    "    debugger_hook_config =False,\n",
    "    disable_profiler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_s3_uri = ''# Path to training data\n",
    "validate_s3_uri = '' # Path to validation data\n",
    "\n",
    "if enable_s3_shard:\n",
    "    train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "else :\n",
    "    train_input = TrainingInput(train_s3_uri)\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "\n",
    "inputs = {training_channel_name:train_input, evaluation_channel_name:val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
